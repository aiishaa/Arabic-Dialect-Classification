{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Fetching.ipynb",
      "provenance": [],
      "mount_file_id": "1iK2yMnGjoiE_i1ITH-tioTkFInwfBVZg",
      "authorship_tag": "ABX9TyOs2gBp3qiO7/iRBlv6BN7Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiishaa/Arabic-Dialect-Classification/blob/main/Data_Fetching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdhYgK_cvyyT",
        "outputId": "35dc4de1-c7cc-435e-92a1-3b18a87bf678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"1055620304465215616\":\"@MahmoudWaked7 @maganenoo ÙÙŠ Ø·Ø±ÙŠÙ‚ Ù…Ø·Ø±ÙˆØ­ Ù…Ø±ÙƒØ² Ø¨Ù‡ÙŠØ¬  ÙˆØ§Ù„Ù…Ø±ÙƒØ² Ø§Ù„ÙŠ Ø§Ù„ÙŠ Ø¬Ù…Ø¨Ù‡ Ø§Ø³Ù…Ù‡ Ø§ÙŠÙ‡ğŸ˜‚ğŸ˜‚\"}\n",
            "{\"1057418989293485952\":\"@mycousinvinnyys @hanyamikhail1 Ù…ØªÙ‡ÙŠØ§Ù„ÙŠ Ø¯ÙŠ Ø´ÙƒÙˆÙ„Ø§ØªÙ‡ Ø§Ù„Ù‡Ø§Ù„ÙˆÙŠÙ†  ÙÙŠÙ† Ø§Ù„Ù…Ø­Ù„ Ø¯Ù‡\"}\n",
            "<Response [200]>\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import base64\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "global str\n",
        "\n",
        "url = \"https://recruitment.aimtechnologies.co/ai-tasks\"\n",
        "headers = {\n",
        "  'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "#payload=\"[1055620304465215616\\\", \\\"1057418989293485952\\\"]\"\n",
        "payload=\"[\\\"1055620304465215616\\\"]\"\n",
        "response = requests.post(url, headers=headers, data=payload)\n",
        "print(response.text)\n",
        "\n",
        "payload=\"[\\\"1057418989293485952\\\"]\"\n",
        "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "print(response.text)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/dialect_dataset.csv')\n",
        "nrows = len(df)\n",
        "#sample_size = 5000\n",
        "#df = df.groupby('dialect').apply(lambda x: x.sample(sample_size))\n",
        "#print(len(df))\n",
        "\n",
        "#random_df = df.sample(frac=1)\n",
        "id = df[\"id\"].to_numpy()\n",
        "dialect = df[\"dialect\"].to_numpy()\n",
        "print(dialect)\n",
        "print(df['dialect'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbjNwLgjwWhM",
        "outputId": "96229d38-a92e-4657-86f1-9e68726a0441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IQ' 'IQ' 'IQ' ... 'BH' 'BH' 'BH']\n",
            "0         IQ\n",
            "1         IQ\n",
            "2         IQ\n",
            "3         IQ\n",
            "4         IQ\n",
            "          ..\n",
            "458192    BH\n",
            "458193    BH\n",
            "458194    BH\n",
            "458195    BH\n",
            "458196    BH\n",
            "Name: dialect, Length: 458197, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping dialects to their indexes\n",
        "data_classes = (df['dialect'].unique())\n",
        "encoded_data, mapping_index = pd.Series(data_classes).factorize()\n",
        "df['dialect'].replace(mapping_index,\n",
        "                        encoded_data, inplace=True)\n",
        "print(df['dialect'])\n",
        "dialect = df[\"dialect\"].to_numpy()\n",
        "print(dialect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pvEFfViwt6H",
        "outputId": "74f3a66c-6444-485d-d276-b58026d24c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          0\n",
            "1          0\n",
            "2          0\n",
            "3          0\n",
            "4          0\n",
            "          ..\n",
            "458192    17\n",
            "458193    17\n",
            "458194    17\n",
            "458195    17\n",
            "458196    17\n",
            "Name: dialect, Length: 458197, dtype: int64\n",
            "[ 0  0  0 ... 17 17 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The API will return a dictionary where the keys are the ids, and the values are the text\n",
        "i = 0\n",
        "dict = [{}]\n",
        "while i in range (458197):\n",
        "  Payload = []\n",
        "  ids = id[i:i+1000]\n",
        "  for ID in ids:\n",
        "    temp = str(ID)\n",
        "    temp = '\"{}\"'.format(temp)\n",
        "    Payload.append(temp)\n",
        "\n",
        "  # Printing list using translate Method ( a list without single quotes)\n",
        "  translation = {39: None}\n",
        "  Payload = str(Payload).translate(translation)\n",
        "  response = requests.post( url, headers=headers, data=Payload)\n",
        "  dict.append(response.json())\n",
        "  i+=1000\n",
        "  \n",
        "print(len(dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ehNvMrhxCyJ",
        "outputId": "ef75b7bc-52f9-4f67-a529-b6469d2bed9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert from list of dictionaries to a dictionary\n",
        "from collections import defaultdict\n",
        "res = defaultdict(list)\n",
        "{res[key].append(sub[key]) for sub in dict for key in sub} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxsIrQCQx4eh",
        "outputId": "52a77840-01a5-4711-e2a5-1879ff19ad61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{None}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the API texts in a dataframe\n",
        "sentences = []\n",
        "for key in res:\n",
        "  strr = str(res[str(key)])\n",
        "  sentences.append(strr)\n",
        "\n",
        "df['text'] = sentences\n",
        "print(df['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsWlb2i4yL4V",
        "outputId": "708cb60c-2703-460e-9c29-8fca4b35d7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         ['@Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØº...\n",
            "1         ['@7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .....\n",
            "2                       ['@KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ']\n",
            "3            ['@HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’']\n",
            "4                    ['@hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº']\n",
            "                                ...                        \n",
            "458192            ['@Al_mhbaa_7 Ù…Ø¨Ø³ÙˆØ·ÙŠÙ† Ù…Ù†Ùƒ Ø§Ù„Ù„ÙŠ Ø¨Ø§Ø³Ø·Ø§Ù†Ø§ğŸ˜…']\n",
            "458193     ['@Zzainabali @P_ameerah ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ÙŠÙ†Ø¯Ù‡ Ø§Ø¨Ø´ ÙŠØ®ØªÙŠ']\n",
            "458194    ['@Al_mhbaa_7 Ø´Ùˆ Ø¹Ù…Ù„Ù†Ø§ Ù„Ùƒ Ø­Ù†Ø§ ØªÙ‡Ø±Ø¨ÙŠ Ù…Ù†Ù†Ø§ Ø§Ø­Ù†Ø§ ...\n",
            "458195      ['@haneenalmwla Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙÙŠÙ‡Ø§ ÙˆØ¨Ø§Ù„Ø¹Ø§ÙÙŠÙ‡ ğŸ˜‹ğŸ˜‹ğŸ˜‹']\n",
            "458196        ['@jolnar121 Ø§Ù„Ø³Ø­Ù„Ù‡ Ø¶ÙŠÙÙŠ ÙŠ Ø¨ØªØ·Ù„Ø¹ Ù„Ùƒ Ø³Ø­Ù„ÙŠÙ‡ğŸ˜…ğŸ˜…']\n",
            "Name: text, Length: 458197, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the dataframe in a csv file for the preprocessing phase\n",
        "df.to_csv('/content/drive/MyDrive/texts.csv')"
      ],
      "metadata": {
        "id": "KkJLQDCjyXiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/texts.csv')\n",
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR2xvjri1NC5",
        "outputId": "c7e52dd8-a905-4be6-f072-206167187bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                   id  dialect  \\\n",
            "0           0  1175358310087892992        0   \n",
            "1           1  1175416117793349632        0   \n",
            "2           2  1175450108898565888        0   \n",
            "3           3  1175471073770573824        0   \n",
            "4           4  1175496913145217024        0   \n",
            "\n",
            "                                                text  \n",
            "0  ['@Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØº...  \n",
            "1  ['@7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .....  \n",
            "2                ['@KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ']  \n",
            "3     ['@HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’']  \n",
            "4             ['@hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº']  \n"
          ]
        }
      ]
    }
  ]
}